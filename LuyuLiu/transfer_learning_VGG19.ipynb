{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_VGG19.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/JialinLiOSU/ML-Final-Project/blob/master/transfer_learning_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MuHFiJd3JFaa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import keras\n",
        "# from vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "# from imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection  import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c4x3QTKTVhHB",
        "outputId": "6e3790f0-8fba-44ab-b011-87453395f374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sIDUFY6XKpEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b5520e3-264b-4fb8-b32b-5097c3e5685e"
      },
      "cell_type": "code",
      "source": [
        "# Loading the training data\n",
        "# PATH = os.getcwd()\n",
        "# Define data path\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/region map'\n",
        "data_dir_list = os.listdir(data_path)     \n",
        "print(data_dir_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['us', 'world', 'south_korea', 'china']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4WVIjfOJK0su",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def VGG_19(weights_path=None, input_tensor=None):\n",
        "    img_input = input_tensor\n",
        "# Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='last_layer')(x)\n",
        "\n",
        "\n",
        "    return Model(img_input, x, name='vgg19')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g1aQTqBzLnQ7",
        "outputId": "455b5325-0ade-4cf1-ccdd-7d5e798a779f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "img_data_list=[]\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
        "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\tfor img in img_list:\n",
        "\t\timg_path = data_path + '/'+ dataset + '/'+ img\n",
        "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
        "\t\tx = image.img_to_array(img)\n",
        "\t\tx = np.expand_dims(x, axis=0)\n",
        "\t\tx = preprocess_input(x)\n",
        "#\t\tx = x/255\n",
        "# \t\tprint('Input image shape:', x.shape)\n",
        "\t\timg_data_list.append(x)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the images of dataset-us\n",
            "\n",
            "Loaded the images of dataset-world\n",
            "\n",
            "Loaded the images of dataset-south_korea\n",
            "\n",
            "Loaded the images of dataset-china\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M2gODdgqXFTG",
        "outputId": "63711187-7baf-4e01-e374-2de1ec57b16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "img_data = np.array(img_data_list)\n",
        "#img_data = img_data.astype('float32')\n",
        "print (img_data.shape)\n",
        "img_data=np.rollaxis(img_data,1,0)\n",
        "print (img_data.shape)\n",
        "img_data=img_data[0]\n",
        "print (img_data.shape)\n",
        "\n",
        "#Training the feature extraction also\n",
        "batch_size=32\n",
        "# epochs_list=[20,40,60,80,100]\n",
        "epochs=100\n",
        "layer_inx_list=[-3,-4,-5,-6,-7,-8,-9,-10]\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 4\n",
        "num_img_each_total=1100\n",
        "num_img_each_list=[i for i in range(500,1100,100)] # 2\n",
        "\n",
        "print(num_img_each_list)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4009, 1, 224, 224, 3)\n",
            "(1, 4009, 224, 224, 3)\n",
            "(4009, 224, 224, 3)\n",
            "[500, 600, 700, 800, 900, 1000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Fwu5060GYClx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.optimizers import SGD\n",
        "import cv2, numpy as np\n",
        "from keras.layers import Activation, Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import merge\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from scipy.misc import imread\n",
        "from scipy.misc import imresize\n",
        "from keras.utils import plot_model \n",
        "\n",
        "data_location = \"/content/drive/My Drive/Colab Notebooks/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iAfWRxnJXnA5",
        "outputId": "c19ca4de-bcff-4ac1-f1aa-7118153e776d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5069
        }
      },
      "cell_type": "code",
      "source": [
        "for num_img_each in num_img_each_list:\n",
        "\n",
        "    num_of_samples = num_img_each*num_classes\n",
        "    labels = np.ones((num_of_samples,),dtype='int64')\n",
        "    X1=img_data[0:num_img_each,]\n",
        "    X2=img_data[num_img_each_total:num_img_each_total+num_img_each]\n",
        "    X3=img_data[num_img_each_total*2:num_img_each_total*2+num_img_each]\n",
        "    X4=img_data[num_img_each_total*3:num_img_each_total*3+num_img_each]\n",
        "    X=np.concatenate((X1,X2,X3,X4),axis=0)\n",
        "\n",
        "    labels[0:num_img_each]=0\n",
        "    labels[num_img_each:num_img_each*2]=1\n",
        "    labels[num_img_each*2:num_img_each*3]=2\n",
        "    labels[num_img_each*3:num_img_each*4]=3\n",
        "    # names = ['china','south_korea','us','world']\n",
        "    # convert class labels to on-hot encoding\n",
        "    Y = np_utils.to_categorical(labels, num_classes)\n",
        "    #Shuffle the dataset\n",
        "    x,y = shuffle(X,Y, random_state=2)\n",
        "    # Split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
        "    print (\"num_img_each:\",num_img_each)\n",
        "\n",
        "    for layer_inx in layer_inx_list:\n",
        "  \n",
        "        image_input = Input(shape=(224, 224, 3))\n",
        "        model = VGG_19(weights_path=data_location, input_tensor=image_input)\n",
        "        print (\"layer_inx:\",layer_inx)\n",
        "        model.load_weights(data_location)\n",
        "\n",
        "        last_layer = model.get_layer('last_layer').output\n",
        "        x= Flatten(name='flatten')(last_layer)\n",
        "        x = Dense(128, activation='relu', name='fc1')(x)\n",
        "        x = Dense(128, activation='relu', name='fc2')(x)\n",
        "        out = Dense(num_classes, activation='softmax', name='output')(x)\n",
        "        custom_vgg_model2 = Model(image_input, out)\n",
        "\n",
        "        # freeze all the layers except the dense layers\n",
        "        for layer in custom_vgg_model2.layers[:layer_inx]:\n",
        "            layer.trainable = False\n",
        "            \n",
        "        custom_vgg_model2.summary()\n",
        "        \n",
        "        custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "        t=time.time()\n",
        "        #\tt = now()\n",
        "        hist = custom_vgg_model2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "        print('Training time: %s' % (time.time()-t))\n",
        "        (loss, accuracy) = custom_vgg_model2.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "        print()\n",
        "        str1=\"Batch_size: \"+str(batch_size)+' epochs: '+str(epochs)+'\\n'\n",
        "        str2=\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100)+'\\n'\n",
        "        str3='Training time: ' + str (time.time()-t)+'\\n'\n",
        "        str4='num_img_each: ' + str (num_img_each)+'\\n'\n",
        "        str5='layer_inx: ' + str (layer_inx)+'\\n'\n",
        "        data_path = '/content/drive/My Drive/Experiment results/'\n",
        "        filename='Experiment_results_pretrained_big_training_size'+'.txt'\n",
        "        filename=data_path+'Experiment_results_pretrained_big_training_size'+'.txt'\n",
        "        file = open(filename,'a')\n",
        "        file.write(str4) \n",
        "        file.write(str5)\n",
        "        file.write(str1) \n",
        "        file.write(str2)\n",
        "        file.write(str3)\n",
        "        file.close()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_img_each: 500\n",
            "layer_inx: -3\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "last_layer (MaxPooling2D)    (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 23,252,804\n",
            "Trainable params: 3,228,420\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1800 samples, validate on 200 samples\n",
            "Epoch 1/100\n",
            "1800/1800 [==============================] - 27s 15ms/step - loss: 2.5858 - acc: 0.8222 - val_loss: 0.0192 - val_acc: 0.9950\n",
            "Epoch 2/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.2058 - acc: 0.9844 - val_loss: 0.3824 - val_acc: 0.9700\n",
            "Epoch 3/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.1239 - acc: 0.9894 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 18/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 24/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 27/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 39/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 47/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 50/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 51/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 53/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 59/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 60/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 65/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 66/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 67/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 72/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 73/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 74/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 82/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 83/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 84/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 85/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 86/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 87/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 88/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 94/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 99/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Epoch 100/100\n",
            "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
            "Training time: 2073.581554174423\n",
            "200/200 [==============================] - 4s 21ms/step\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fd4fd52eaae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Experiment_results_pretrained_big_training_size'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Experiment_results_pretrained_big_training_size'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Experiment results/Experiment_results_pretrained_big_training_size.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9MLimdf9k4CN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/My Drive/Experiment results/'\n",
        "str1=\"Batch_size: \"\n",
        "filename=data_path+'Experiment_results_pretrained_big_training_size'+'.txt'\n",
        "file = open(filename,'a')\n",
        "file.write(str1) \n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BWoLI_ymmBUk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}