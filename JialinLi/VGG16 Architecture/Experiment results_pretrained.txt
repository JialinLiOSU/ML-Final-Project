model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')
model.summary()
last_layer = model.get_layer('fc2').output
#x= Flatten(name='flatten')(last_layer)
out = Dense(num_classes, activation='softmax', name='output')(last_layer)
custom_vgg_model = Model(image_input, out)
custom_vgg_model.summary()

Batch_size: 32 epochs: 20
[INFO] loss=0.6989, accuracy: 87.5000%
Training time: 1193.925316810608
Batch_size: 32 epochs: 40
[INFO] loss=0.5705, accuracy: 87.5000%
Training time: 2415.3966727256775
Batch_size: 32 epochs: 60
[INFO] loss=0.6956, accuracy: 90.0000%
Training time: 3590.4963212013245
Batch_size: 32 epochs: 80
[INFO] loss=0.9050, accuracy: 85.0000%
Training time: 4785.872489690781
Batch_size: 32 epochs: 100
[INFO] loss=0.8455, accuracy: 90.0000%
Training time: 6061.584914445877

last_layer = model.get_layer('block5_pool').output
x= Flatten(name='flatten')(last_layer)
x = Dense(128, activation='relu', name='fc1')(x)
x = Dense(128, activation='relu', name='fc2')(x)
out = Dense(num_classes, activation='softmax', name='output')(x)

Batch_size: 32 epochs: 20
[INFO] loss=0.4874, accuracy: 95.0000%
Training time: 1189.2797923088074
Batch_size: 32 epochs: 40
[INFO] loss=0.5902, accuracy: 92.5000%
Training time: 2373.60866189003
Batch_size: 32 epochs: 60
[INFO] loss=0.0001, accuracy: 100.0000%
Training time: 3588.3396973609924
Batch_size: 32 epochs: 80
[INFO] loss=0.0000, accuracy: 100.0000%
Training time: 4809.08182144165
Batch_size: 32 epochs: 100
[INFO] loss=4.0295, accuracy: 75.0000%
Training time: 5873.26944732666
Batch_size: 32 epochs: 20
[INFO] loss=0.4030, accuracy: 97.5000%
Training time: 1178.554514169693
Batch_size: 32 epochs: 40
[INFO] loss=6.8502, accuracy: 57.5000%
Training time: 2351.3331668376923
Batch_size: 32 epochs: 60
[INFO] loss=12.8945, accuracy: 20.0000%
Training time: 3519.1072936058044
Batch_size: 32 epochs: 80
[INFO] loss=0.7248, accuracy: 95.0000%
Training time: 4707.335140943527
Batch_size: 32 epochs: 100
[INFO] loss=6.0443, accuracy: 62.5000%
Training time: 5979.433037281036
