{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JialinLiOSU/ML-Final-Project/blob/master/transfer_learning_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fwu5060GYClx",
    "outputId": "84231348-3b67-4459-eeb1-1d615ef0f690"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import merge, Input\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVAodt6RYMLS"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "#     img_path = 'elephant.jpg'\n",
    "#     img = image.load_img(img_path, target_size=(224, 224))\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     x = preprocess_input(x)\n",
    "#     print('Input image shape:', x.shape)\n",
    "\n",
    "#     preds = model.predict(x)\n",
    "#     print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c4x3QTKTVhHB",
    "outputId": "89554fb2-22b5-400c-b321-d137fa8644b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIDUFY6XKpEc"
   },
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "# PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = '/content/drive/My Drive/region map'\n",
    "data_dir_list = os.listdir(data_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "g1aQTqBzLnQ7",
    "outputId": "e2665203-f6bb-49a8-b645-ce811ad1281f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-china\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-south_korea\n",
      "\n",
      "Loaded the images of dataset-us\n",
      "\n",
      "Loaded the images of dataset-world\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tfor img in img_list:\n",
    "\t\timg_path = data_path + '/'+ dataset + '/'+ img\n",
    "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "# \t\tx = x/255\n",
    "# \t\tprint('Input image shape:', x.shape)\n",
    "\t\timg_data_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "M2gODdgqXFTG",
    "outputId": "a8f877cd-776e-4c80-b86a-56600da78471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 224, 224, 3)\n",
      "(1, 6000, 224, 224, 3)\n",
      "(6000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "#img_data = img_data.astype('float32')\n",
    "print (img_data.shape)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)\n",
    "\n",
    "#Training the feature extraction also\n",
    "batch_size=32   #change batch_size\n",
    "# epochs_list=[20,40,60,80,100]\n",
    "epochs=20\n",
    "layer_inx_list=[-3,-4,-5,-6,-7,-8,-9,-10]\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "num_img_each_total=1500\n",
    "num_img_each_list=[i for i in range(100,1500,200)] # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iAfWRxnJXnA5",
    "outputId": "deb7a215-986f-4bc8-d7d0-a82763e2fe57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_img_each: 900\n"
     ]
    }
   ],
   "source": [
    "num_img_each=1100\n",
    "num_of_samples = num_img_each*num_classes\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "X1=img_data[0:num_img_each]\n",
    "X2=img_data[num_img_each_total:num_img_each_total+num_img_each]\n",
    "X3=img_data[num_img_each_total*2:num_img_each_total*2+num_img_each]\n",
    "X4=img_data[num_img_each_total*3:num_img_each_total*3+num_img_each]\n",
    "X=np.concatenate((X1,X2,X3,X4),axis=0)\n",
    "\n",
    "labels[0:num_img_each]=0\n",
    "labels[num_img_each:num_img_each*2]=1\n",
    "labels[num_img_each*2:num_img_each*3]=2\n",
    "labels[num_img_each*3:num_img_each*4]=3\n",
    "del img_data, img_data_list\n",
    "# names = ['china','south_korea','us','world']\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(X,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print (\"num_img_each:\",num_img_each)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBYQkru-XtFq"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13467
    },
    "colab_type": "code",
    "id": "BWoLI_ymmBUk",
    "outputId": "75efd50b-074f-4c00-c680-749d85e4516e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "layer_inx: -3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 3,228,420\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 24s 8ms/step - loss: 6.3113 - acc: 0.5934 - val_loss: 0.3119 - val_acc: 0.9778\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.2759 - acc: 0.9792 - val_loss: 0.2500 - val_acc: 0.9806\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.2187 - acc: 0.9851 - val_loss: 0.1464 - val_acc: 0.9889\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.1324 - acc: 0.9910 - val_loss: 0.2189 - val_acc: 0.9819\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0775 - acc: 0.9941 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0918 - val_acc: 0.9931\n",
      "Training time: 349.3097457885742\n",
      "720/720 [==============================] - 6s 8ms/step\n",
      "\n",
      "layer_inx: -4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 3,228,420\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 8.6293 - acc: 0.4583 - val_loss: 8.0370 - val_acc: 0.5014\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 6.7522 - acc: 0.5774 - val_loss: 0.4007 - val_acc: 0.9722\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 0.2882 - acc: 0.9774 - val_loss: 0.4181 - val_acc: 0.9667\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0517 - acc: 0.9958 - val_loss: 0.0224 - val_acc: 0.9986\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.1275 - acc: 0.9913 - val_loss: 0.1791 - val_acc: 0.9889\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0457 - acc: 0.9965 - val_loss: 0.1119 - val_acc: 0.9931\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0280 - acc: 0.9983 - val_loss: 0.0937 - val_acc: 0.9931\n",
      "Training time: 347.44191431999207\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n",
      "layer_inx: -5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 3,228,420\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 4.7508 - acc: 0.6920 - val_loss: 0.1661 - val_acc: 0.9875\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.1931 - acc: 0.9847 - val_loss: 0.6728 - val_acc: 0.9458\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0776 - acc: 0.9948 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 17s 6ms/step - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9958\n",
      "Training time: 346.75519919395447\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n",
      "layer_inx: -6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 5,588,228\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 11.9987 - acc: 0.2524 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Training time: 359.6482615470886\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n",
      "layer_inx: -7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 7,948,036\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 11.9621 - acc: 0.2563 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 18s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Training time: 372.67268776893616\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n",
      "layer_inx: -8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 10,307,844\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 20s 7ms/step - loss: 12.0440 - acc: 0.2483 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.0942 - acc: 0.2497 - val_loss: 12.0662 - val_acc: 0.2514\n",
      "Training time: 386.89082074165344\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n",
      "layer_inx: -9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 10,307,844\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 20s 7ms/step - loss: 12.0691 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 19s 7ms/step - loss: 12.1166 - acc: 0.2483 - val_loss: 11.9766 - val_acc: 0.2569\n",
      "Training time: 388.70032954216003\n",
      "720/720 [==============================] - 5s 6ms/step\n",
      "\n",
      "layer_inx: -10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,943,108\n",
      "Trainable params: 12,667,652\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n",
      "Train on 2880 samples, validate on 720 samples\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 22s 8ms/step - loss: 11.9824 - acc: 0.2531 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 11/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 12/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 13/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 14/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 15/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 16/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 17/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 18/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 19/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Epoch 20/20\n",
      "2880/2880 [==============================] - 21s 7ms/step - loss: 12.0214 - acc: 0.2542 - val_loss: 12.3572 - val_acc: 0.2333\n",
      "Training time: 415.9129319190979\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer_inx in layer_inx_list:\n",
    "    image_input = Input(shape=(224, 224, 3))\n",
    "    model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "    print (\"layer_inx:\",layer_inx)\n",
    "        \n",
    "\n",
    "    last_layer = model.get_layer('block5_pool').output\n",
    "    x= Flatten(name='flatten')(last_layer)\n",
    "    x = Dense(128, activation='relu', name='fc1')(x)\n",
    "    x = Dense(128, activation='relu', name='fc2')(x)\n",
    "    out = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    custom_vgg_model2 = Model(image_input, out)\n",
    "\n",
    "    # freeze all the layers except the dense layers\n",
    "    for layer in custom_vgg_model2.layers[:layer_inx]:\n",
    "        layer.trainable = False\n",
    "            \n",
    "    custom_vgg_model2.summary()\n",
    "        \n",
    "    custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "    t=time.time()\n",
    "    #\tt = now()\n",
    "    hist = custom_vgg_model2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "    print('Training time: %s' % (time.time()-t))\n",
    "    (loss, accuracy) = custom_vgg_model2.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
    "\n",
    "    print()\n",
    "    str1=\"Batch_size: \"+str(batch_size)+' epochs: '+str(epochs)+'\\n'\n",
    "    str2=\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100)+'\\n'\n",
    "    str3='Training time: ' + str (time.time()-t)+'\\n'\n",
    "    str4='num_img_each: ' + str (num_img_each)+'\\n'\n",
    "    str5='layer_inx: ' + str (layer_inx)+'\\n'\n",
    "    data_path = '/content/drive/My Drive/Experiment results/'\n",
    "    filename='Experiment_results_pretrained_6000'+'.txt'\n",
    "    filename=data_path+ filename\n",
    "    file = open(filename,'a')\n",
    "    file.write(str4) \n",
    "    file.write(str5)\n",
    "    file.write(str1) \n",
    "    file.write(str2)\n",
    "    file.write(str3)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_2uet0_TrLi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transfer_learning_VGG16.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
